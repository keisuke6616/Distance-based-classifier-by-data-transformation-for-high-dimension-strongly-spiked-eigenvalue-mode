{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Figure3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keisuke6616/Distance-based-classifier-by-data-transformation-for-high-dimension-strongly-spiked-eigenvalue-mode/blob/master/Figure3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "dqziUMVq5G6U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import numpy.linalg as la\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KLTzNicg5TBl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Figure3"
      ]
    },
    {
      "metadata": {
        "id": "47xri_Uz5TcH",
        "colab_type": "code",
        "outputId": "07d02a7c-6327-4abf-ba0d-14464e0b10d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "cell_type": "code",
      "source": [
        "t1 = time.time()\n",
        "np.random.seed(42)\n",
        "fnc = function()\n",
        "mls= ML_high_sim()\n",
        "\n",
        "D = [2**s for s in range(5, 11)]\n",
        "index = [i for i in range(len(D))]\n",
        "K = 2\n",
        "\n",
        "ite = 1000\n",
        "result = np.zeros((len(D), K, 2))\n",
        "\n",
        "\n",
        "for d, pc in zip(D, index):\n",
        "    print('Dimension : {}'.format(d))\n",
        "    \n",
        "    n1 = int(np.ceil(d**(2/5)))\n",
        "    n2 = 2 * n1\n",
        "    N = [n1, n2]\n",
        "    \n",
        "    mu1 = np.zeros(d)\n",
        "    mu2 = np.array([0 for i in range(d - int(np.ceil(np.sqrt(d))))] + [1 for i in range(int(np.ceil(np.sqrt(d))))])\n",
        "    mu = [mu1, mu2]\n",
        "    \n",
        "    Sigma1 = np.diag([d**(2/3), d**(1/2)] + [1 for i in range(d-2)])    \n",
        "    Sigma2 = 2 * Sigma1\n",
        "    Sigma = [Sigma1, Sigma2]\n",
        "    value, vec, Gamma = [0]*2, [0]*2, [0]*2\n",
        "    for i in range(2):\n",
        "        value[i], vec[i] = fnc.eig_sort(Sigma[i])\n",
        "        Gamma[i] = np.sqrt(value[i]).reshape(-1, d) * vec[i]\n",
        "    \n",
        "    for l in range(ite):\n",
        "        train, test = [0]*2, [0]*2\n",
        "        for i in range(2):\n",
        "            Z = np.random.normal(0, 1, (N[i], d))\n",
        "            train[i] = np.dot(Z, Gamma[i].T) + mu[i]\n",
        "            \n",
        "            z = np.random.normal(0, 1, d)\n",
        "            test[i] = np.dot(z, Gamma[i].T) + mu[i]\n",
        "            \n",
        "        # Learn\n",
        "        ml.NRM_learn(train[0], train[1], [2, 2])\n",
        "        \n",
        "        for i in range(2):\n",
        "            classifier1 = ml.DBDA(test[i])\n",
        "            classifier2 = ml.T_DBDA(test[i])\n",
        "            classifier = [classifier1, classifier2]\n",
        "            for k in range(2):\n",
        "                if (-1)**i * classifier[k] < 0:\n",
        "                    result[pc, k, i] += 1\n",
        "\n",
        "    print('DBDA : {}'.format(result[pc, 0]))\n",
        "    print('T_DBDA : {}'.format(result[pc, 1]))\n",
        "    print('')\n",
        "    \n",
        "\n",
        "t2 = time.time()\n",
        "print('Calculation time : {}'.format(t2 - t1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dimension : 32\n",
            "DBDA : [640. 615.]\n",
            "T_DBDA : [683. 551.]\n",
            "\n",
            "Dimension : 64\n",
            "DBDA : [685. 627.]\n",
            "T_DBDA : [720. 596.]\n",
            "\n",
            "Dimension : 128\n",
            "DBDA : [686. 606.]\n",
            "T_DBDA : [757. 597.]\n",
            "\n",
            "Dimension : 256\n",
            "DBDA : [687. 654.]\n",
            "T_DBDA : [740. 658.]\n",
            "\n",
            "Dimension : 512\n",
            "DBDA : [690. 673.]\n",
            "T_DBDA : [792. 681.]\n",
            "\n",
            "Dimension : 1024\n",
            "DBDA : [723. 662.]\n",
            "T_DBDA : [829. 738.]\n",
            "\n",
            "Calculation time : 243.48672723770142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a3a7P0njeLDv",
        "colab_type": "code",
        "outputId": "eaa19b75-5a1c-4bde-b215-31914b26bf20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "cell_type": "code",
      "source": [
        "error = np.ones((len(D), K, 2)) - result / ite\n",
        "log2_D = np.log2(D)\n",
        "\n",
        "plt.figure(figsize=(13, 5))\n",
        "for i in range(2):\n",
        "    plt.subplot(1, 2, i+1)\n",
        "    plt.plot(log2_D, error[:, 0, i], 'o--', color='blue', label='DBDA')\n",
        "    plt.plot(log2_D, error[:, 1, i], 'o--', color='red', label='T-DBDA')\n",
        "    plt.ylim(0.1, 0.45)\n",
        "    \n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fd0ada43358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAv4AAAEzCAYAAABJ+wdOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngOAPAAAA2ADBHwAAALCB/w9X3V64eNXDyQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fd0ad95d7f0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "EyoUURL55T_a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Function"
      ]
    },
    {
      "metadata": {
        "id": "TDa28Fl-5Vzl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import numpy.linalg as la\n",
        "from scipy.stats import norm\n",
        "\n",
        "\n",
        "class function:\n",
        "    \n",
        "    \n",
        "################################ prepare ########################################################\n",
        "    \n",
        "            \n",
        "    def eig_sort(self, S):\n",
        "        value, vec = la.eig(S)\n",
        "        idx = value.argsort()[::-1]\n",
        "        P = value[idx]\n",
        "        Q = vec.T[idx]\n",
        "\n",
        "        return (P, Q.T)\n",
        "    \n",
        "    \n",
        "    \n",
        "    def  svd_sort(self, S):\n",
        "        vec_r, value, vec_l = la.svd(S)\n",
        "        idx = value.argsort()[::-1]\n",
        "        P = value[idx]\n",
        "        Q_r = vec_r.T[idx]\n",
        "        Q_l = vec_l.T[idx]\n",
        "        \n",
        "        return (Q_r.T, P, Q_l.T)\n",
        " \n",
        "\n",
        "\n",
        "    def data(self, X, bias=False):\n",
        "        self.bias = bias\n",
        "        self.N, self.D = X.shape\n",
        "        self.X = X\n",
        "        self.mean = np.zeros(self.N)\n",
        "        if bias == False:\n",
        "            self.mean = np.array([np.mean(self.X, axis=0)]*self.N)\n",
        "            self.S = np.dot(self.X - self.mean, (self.X - self.mean).T) / (self.N - 1)\n",
        "            self.value, self.vec = self.eig_sort(self.S)\n",
        "        \n",
        "        elif bias == True:\n",
        "            self.S = np.dot(self.X, self.X.T) / self.N\n",
        "            self.value, self.vec = self.eig_sort(self.S)\n",
        "    \n",
        "        \n",
        "    def Cov(self):\n",
        "        return self.S\n",
        "    \n",
        "    def Mean(self):\n",
        "        return self.mean\n",
        "    \n",
        "    \n",
        "    def sign_ad(self, Z): \n",
        "        X = Z.T[:self.N+1]\n",
        "        Y = self.vec.T[:self.N+1]\n",
        "        for i in range(self.N):\n",
        "            sign = np.dot(X[i], Y[i])\n",
        "            if sign < 0:\n",
        "                Y[i] = - Y[i]\n",
        "\n",
        "        return Y.T\n",
        "    \n",
        "    \n",
        "    \n",
        "    def P(self):\n",
        "        one = np.array([1 for i in range(self.N)])\n",
        "        mat = np.eye(self.N) - np.einsum('i, j -> ij', one, one) / self.N\n",
        "        return mat\n",
        "    \n",
        "    \n",
        "    \n",
        "###################### check SSE Model ###############################\n",
        "   \n",
        "    def check_sse(self):\n",
        "        value = self.CDM_value()\n",
        "        SDcross = self.SDcross\n",
        "        phi, tau = [0]*self.n2, [0]*self.n2\n",
        "        mhat = self.n2 - 2\n",
        "        \n",
        "        def kappa(n):\n",
        "            return np.sqrt(1 / n * np.log(n))\n",
        "    \n",
        "        for j in range(self.n2):\n",
        "            if j == 0:\n",
        "                phi[j] = np.trace(np.dot(SDcross, SDcross.T))\n",
        "            else:\n",
        "                phi[j] = np.trace(np.dot(SDcross, SDcross.T)) - np.sum(value[i]**2 for i in range(j))\n",
        "        \n",
        "        for j in range(self.n2 - 1):\n",
        "            tau[j] = phi[j + 1] / phi[j]\n",
        "        \n",
        "        for j in range(self.n2 - 1):\n",
        "            crit = tau[j] * (1 + (j + 1) * kappa(self.N))\n",
        "            if crit > 1:\n",
        "                mhat = j \n",
        "                break\n",
        "\n",
        "                \n",
        "        mhat = np.min([mhat, self.n2 - 2])\n",
        "        \n",
        "        return mhat\n",
        "    \n",
        "    \n",
        "    \n",
        "######################## estimation of eigen vector ########################\n",
        "    \n",
        "    def et_vec(self, value, M):\n",
        "        vec = np.zeros((self.D, M))    \n",
        "        \n",
        "        if self.bias == False:\n",
        "            for m in range(M):\n",
        "                vec.T[m] = np.dot(self.vec.T[m], self.X - self.mean) / np.sqrt((self.N - 1) * value[m])\n",
        "                \n",
        "        if self.bias == True:\n",
        "            for m in range(M):\n",
        "                vec.T[m] = np.dot(self.vec.T[m], self.X) / np.sqrt(self.N * value[m])\n",
        "                \n",
        "        return vec  \n",
        "    \n",
        "    \n",
        "    \n",
        "    def et_vec_self(self, value, M):\n",
        "        vec = np.zeros((M, self.N, self.D))  \n",
        "        \n",
        "        if self.bias == False:\n",
        "            c = np.sqrt(self.N - 1) / (self.N - 2)\n",
        "            for m in range(M):\n",
        "                u_hat = self.vec.T[m]\n",
        "                for n in range(self.N):\n",
        "                    u_hat[n] = - u_hat[n] / (self.N - 1)\n",
        "                    vec[m, n] = c / np.sqrt(value[m]) * np.dot(u_hat, self.X - self.mean)\n",
        "\n",
        "        if self.bias == True:\n",
        "            c = np.sqrt(self.N) / (self.N - 1)\n",
        "            for m in range(M):\n",
        "                u_hat = self.vec.T[m]\n",
        "                for n in range(self.N):\n",
        "                    u_hat[n] = -u_hat[n] / self.N\n",
        "                    vec[m, n] = c / np.sqrt(value[m]) * np.dot(u_hat, self.X)\n",
        "                    \n",
        "        return vec\n",
        "    \n",
        "    \n",
        "################################ projection matrix #########################################\n",
        "\n",
        "    def prj(self, vec, M):\n",
        "        prj = np.eye(self.D) - np.sum(np.einsum('i, j -> ij', vec.T[i], vec.T[i]) for i in range(M))\n",
        "        return prj\n",
        "\n",
        "\n",
        "    \n",
        "######################################### dual covariance matrix #######################################\n",
        "    def dual(self):\n",
        "        return (self.value, self.vec)\n",
        "    \n",
        "    def dual_value(self):\n",
        "        return self.value\n",
        "\n",
        "    \n",
        "    \n",
        "########################################### noise-reduction ##############################################\n",
        "    \n",
        "    def NRM_value(self): \n",
        "        value = np.zeros(self.N)\n",
        "        \n",
        "        if self.bias == False:\n",
        "            for j in range(self.N - 2):\n",
        "                value[j] = self.value[j] - (np.trace(self.S) - np.sum(self.value[0 :(j+1)])) / (self.N - j - 2)\n",
        "        \n",
        "        elif self.bias == True:\n",
        "            for j in range(self.N - 1):\n",
        "                value[j] = self.value[j] - (np.trace(self.S) - np.sum(self.value[0 :(j+1)])) / (self.N - j - 1)\n",
        "            \n",
        "        return value\n",
        "    \n",
        "    \n",
        "    \n",
        "    def NRM(self): \n",
        "        M = self.check_sse()\n",
        "        value = self.NRM_value()\n",
        "        spiked_vec = np.zeros((self.D, self.n2))\n",
        "        spiked_vec_self = np.zeros((self.n2, self.N, self.D))\n",
        "        \n",
        "        \n",
        "        if M != 0:\n",
        "            spiked_vec = self.et_vec(value, M)\n",
        "            spiked_vec_self = self.et_vec_self(value, M)\n",
        "\n",
        "        return (value, spiked_vec, spiked_vec_self, M)\n",
        "    \n",
        "    \n",
        "   \n",
        "               \n",
        "        \n",
        "####################################### cross-data-methodology #############################################\n",
        "        \n",
        "    \n",
        "    def CDM_value(self):\n",
        "        n1 = int(np.ceil(self.N / 2))\n",
        "        n2 = self.N - n1\n",
        "        self.n2 = n2\n",
        "        X1, X2 = self.X[:n1], self.X[-n2:]\n",
        "        \n",
        "        if self.bias == False:    \n",
        "            mean1 = np.array([np.mean(X1, axis=0)] * n1)\n",
        "            mean2 = np.array([np.mean(X2, axis=0)] * n2)\n",
        "            \n",
        "            self.SDcross = np.dot(X1 - mean1, (X2 - mean2).T) / np.sqrt((n1 - 1) * (n2 - 1))\n",
        "            value = self.svd_sort(self.SDcross)[1]\n",
        "            \n",
        "        if self.bias == True:\n",
        "            self.SDcross = np.dot(X1, X2.T) / np.sqrt(n1 * n2)\n",
        "            value = self.svd_sort(self.SDcross)[1]\n",
        "            \n",
        "        return value\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    def CDM(self):\n",
        "        M = self.check_sse()\n",
        "        value = self.CDM_value()\n",
        "        spiked_vec = np.zeros((self.D, self.n2))\n",
        "        spiked_vec_self = np.zeros((self.n2, self.N, self.D))\n",
        "        \n",
        "        \n",
        "        if M != 0:\n",
        "            spiked_vec = self.et_vec(value, M)\n",
        "            spiked_vec_self = self.et_vec_self(value, M)\n",
        "\n",
        "        return (value, spiked_vec, spiked_vec_self, M)\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "############################### estiomation of tr(Sigma^2) #################################\n",
        "    \n",
        "        \n",
        "    def ECDM_data(self, X):\n",
        "        N, D = X.shape\n",
        "        n = []\n",
        "        n.append(int(np.ceil(N / 2)))\n",
        "        n.append(N - n[0])\n",
        "\n",
        "        K = [i for i in range(3, 2*N)]\n",
        "        index =  [i for i in range(len(K))]\n",
        "\n",
        "\n",
        "        V = [[], []]\n",
        "        Y = np.zeros((2, len(K), D))\n",
        "        for k, pc in zip(K, index):\n",
        "            dv = int(np.floor(k / 2))\n",
        "\n",
        "            if dv < n[0]:\n",
        "                V[0].append([i for i in range(dv)] + [i for i in range(dv + n[1], N)])  \n",
        "            else:\n",
        "                V[0].append([i for i in range(dv - n[0], dv)])\n",
        "\n",
        "            if dv <= n[0]:\n",
        "                V[1].append([i for i in range(dv, dv + n[1])])\n",
        "            else:\n",
        "                V[1].append([i for i in range(dv - n[0])] + [i for i in range(dv, N)])\n",
        "\n",
        "            for i in range(2):\n",
        "                Y[i, pc] = np.sum(X[V[i][pc]], axis=0) / n[i]\n",
        "\n",
        "        w = 0\n",
        "        for j in range(N):\n",
        "            for i in range(j):\n",
        "                w += np.dot(X[i] - Y[0][i + j - 1], X[j] - Y[1][i + j - 1]) ** 2\n",
        "\n",
        "        u =  n[0] * n[1] / ((n[0] - 1) * (n[1] - 1))\n",
        "        W = 2 * u / (N * (N - 1)) * w\n",
        "\n",
        "        return W\n",
        "    \n",
        "    \n",
        "    \n",
        "    def ECDM(self):\n",
        "        n = []\n",
        "        n.append(int(np.ceil(self.N / 2)))\n",
        "        n.append(self.N - n[0])\n",
        "\n",
        "        K = [i for i in range(3, 2*self.N)]\n",
        "        index =  [i for i in range(len(K))]\n",
        "\n",
        "\n",
        "        V = [[], []]\n",
        "        Y = np.zeros((2, len(K), self.D))\n",
        "        for k, pc in zip(K, index):\n",
        "            dv = int(np.floor(k / 2))\n",
        "\n",
        "            if dv < n[0]:\n",
        "                V[0].append([i for i in range(dv)] + [i for i in range(dv + n[1], self.N)])  \n",
        "            else:\n",
        "                V[0].append([i for i in range(dv - n[0], dv)])\n",
        "\n",
        "            if dv <= n[0]:\n",
        "                V[1].append([i for i in range(dv, dv + n[1])])\n",
        "            else:\n",
        "                V[1].append([i for i in range(dv - n[0])] + [i for i in range(dv, self.N)])\n",
        "\n",
        "            for i in range(2):\n",
        "                Y[i, pc] = np.sum(self.X[V[i][pc]], axis=0) / n[i]\n",
        "\n",
        "        w = 0\n",
        "        for j in range(self.N):\n",
        "            for i in range(j):\n",
        "                w += np.dot(self.X[i] - Y[0][i + j - 1], self.X[j] - Y[1][i + j - 1]) ** 2\n",
        "\n",
        "        u =  n[0] * n[1] / ((n[0] - 1) * (n[1] - 1))\n",
        "        W = 2 * u / (self.N * (self.N - 1)) * w\n",
        "\n",
        "        return W\n",
        "    \n",
        "        \n",
        "    def W_data(self, X, A):\n",
        "        N,  D= X.shape\n",
        "\n",
        "        def nPr(n, r):\n",
        "            import math\n",
        "            c = int(math.factorial(n) / math.factorial(n - r))\n",
        "            return c\n",
        "\n",
        "        w = [0]*3\n",
        "        for i in range(N):\n",
        "            for j in range(N):\n",
        "                if i != j:\n",
        "                    w[0] += np.einsum('i, ij, j', X[i], A, X[j])**2\n",
        "\n",
        "                for s in range(N):\n",
        "                    if i != j and j!= s and s != i:\n",
        "                        w[1] += np.einsum('i, ij, j', X[i], A, X[j]) * np.einsum('j, js, s', X[j], A, X[s])\n",
        "\n",
        "                    for t in range(N):\n",
        "                        if i != j and i != s and i!= t and j != s and j != t and s != t:\n",
        "                            w[2] += np.einsum('i, ij, j', X[i], A, X[j]) * np.einsum('s, st, t', X[s], A, X[t])\n",
        "\n",
        "        W = w[0] / nPr(N, 2) - 2 * w[1] / nPr(N, 3) + w[2] / nPr(N, 4)\n",
        "        \n",
        "        return W\n",
        "    \n",
        "    def W_data_eye(self, X):\n",
        "        N,  D= X.shape\n",
        "\n",
        "        def nPr(n, r):\n",
        "            import math\n",
        "            c = int(math.factorial(n) / math.factorial(n - r))\n",
        "            return c\n",
        "\n",
        "        w = [0]*3\n",
        "        for i in range(N):\n",
        "            for j in range(N):\n",
        "                if i != j:\n",
        "                    w[0] += np.dot(X[i], X[j])**2\n",
        "\n",
        "                for s in range(N):\n",
        "                    if i != j and j!= s and s != i:\n",
        "                        w[1] += np.dot(X[i], X[j]) * np.dot(X[j], X[s])\n",
        "\n",
        "                    for t in range(N):\n",
        "                        if i != j and i != s and i!= t and j != s and j != t and s != t:\n",
        "                            w[2] += np.dot(X[i], X[j]) * np.dot(X[s], X[t])\n",
        "\n",
        "        W = w[0] / nPr(N, 2) - 2 * w[1] / nPr(N, 3) + w[2] / nPr(N, 4)\n",
        "        \n",
        "        return W\n",
        "    \n",
        "    \n",
        "############### T_hat #####################################3\n",
        "\n",
        "    def T_hat(self, X, x):\n",
        "        N, p = X.shape\n",
        "\n",
        "        n = []\n",
        "        n.append(int(np.ceil(N / 2)))\n",
        "        n.append(N - n[0])\n",
        "\n",
        "        K = [i for i in range(3, 2*N)]\n",
        "        index =  [i for i in range(len(K))]\n",
        "\n",
        "\n",
        "        V = [[], []]\n",
        "        Y = np.zeros((2, len(K), p))\n",
        "        y = np.zeros((2, len(K)))\n",
        "        for k, pc in zip(K, index):\n",
        "            dv = int(np.floor(k / 2))\n",
        "\n",
        "            if dv < n[0]:\n",
        "                V[0].append([i for i in range(dv)] + [i for i in range(dv + n[1], N)])   \n",
        "            else:\n",
        "                V[0].append([i for i in range(dv - n[0], dv)])\n",
        "\n",
        "            if dv <= n[0]:\n",
        "                V[1].append([i for i in range(dv, dv + n[1])])\n",
        "            else:\n",
        "                V[1].append([i for i in range(dv - n[0])] + [i for i in range(dv, N)])\n",
        "\n",
        "            for i in range(2):\n",
        "                Y[i, pc] = np.sum(X[V[i][pc]], axis=0) / n[i]\n",
        "                y[i, pc] = np.sum(x[V[i][pc]]) / n[i]\n",
        "\n",
        "        w = 0\n",
        "        for j in range(N):\n",
        "            for i in range(j):\n",
        "                w += np.dot(X[i] - Y[0][i + j - 1], X[j] - Y[1][i + j - 1]) * (x[i] - y[0][i + j - 1]) * (x[j] - y[1][i + j - 1])\n",
        "\n",
        "        u =  n[0] * n[1] / ((n[0] - 1) * (n[1] - 1))\n",
        "        T = 2 * u / (N * (N - 1)) * w\n",
        "\n",
        "        return T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DAeWMoeR5X2w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# ML_high"
      ]
    },
    {
      "metadata": {
        "id": "pj4h5q5Tb2X9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import numpy.linalg as la\n",
        "from scipy.stats import norm\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "\n",
        "class ML_high_sim:\n",
        "######################## prepare ###################################\n",
        "\n",
        "    def __init__(self):\n",
        "        self.fnc = function()\n",
        "        \n",
        "######################### NRM #####################################\n",
        "        \n",
        "    \n",
        "    def NRM_learn(self, X1, X2, M, bias=False):\n",
        "        self.bias = bias\n",
        "        \n",
        "        n1, n2 = X1.shape[0], X2.shape[0]\n",
        "        self.D = X1.shape[1]\n",
        "        self.N = [n1, n2]\n",
        "        self.X = [X1, X2]\n",
        "        \n",
        "        self.cov, self.trS, self.mean = [0]*2, [0]*2, [0]*2\n",
        "        self.diag = [0]*2\n",
        "        self.value, self.vec, self.vec_self = [0]*2, [0]*2, [0]*2\n",
        "        self.M = M\n",
        "\n",
        "        for i in range(2):    \n",
        "            self.fnc.data(self.X[i], bias=self.bias)\n",
        "            self.mean[i] = np.mean(self.X[i], axis=0)\n",
        "            self.cov[i] = np.cov(self.X[i], rowvar=False)\n",
        "            self.trS[i] = np.trace(self.cov[i])\n",
        "            self.diag[i] = np.diag(self.cov[i])\n",
        "            \n",
        "            self.value[i] = self.fnc.NRM_value()\n",
        "            self.vec[i] = self.fnc.et_vec(self.value[i], M[i])\n",
        "            self.vec_self[i] = self.fnc.et_vec_self(self.value[i], M[i])\n",
        "\n",
        "\n",
        "            \n",
        "######################### CDM ####################################\n",
        "\n",
        "    def CDM_learn(self, X1, X2, M, bias=False):\n",
        "        self.bias = bias\n",
        "        \n",
        "        n1, n2 = X1.shape[0], X2.shape[0]\n",
        "        self.D = X1.shape[1]\n",
        "        self.N = [n1, n2]\n",
        "        self.X = [X1, X2]\n",
        "        \n",
        "        self.cov, self.trS, self.mean = [0]*2, [0]*2, [0]*2\n",
        "        self.diag = [0]*2\n",
        "        self.value, self.vec, self.vec_self = [0]*2, [0]*2, [0]*2\n",
        "        self.M = M\n",
        "\n",
        "        for i in range(2):    \n",
        "            self.fnc.data(self.X[i], bias=self.bias)\n",
        "            self.mean[i] = np.mean(self.X[i], axis=0)\n",
        "            self.cov[i] = np.cov(self.X[i], rowvar=False)\n",
        "            self.trS[i] = np.trace(self.cov[i])\n",
        "            self.diag[i] = np.diag(self.cov[i])\n",
        "            \n",
        "            self.value[i] = self.fnc.NRM_value()\n",
        "            self.vec[i] = self.fnc.et_vec(self.value[i], M[i])\n",
        "            self.vec_self[i] = self.fnc.et_vec_self(self.value[i], M[i])\n",
        "    \n",
        "        \n",
        "######################### classifier #################################\n",
        "\n",
        "    def DBDA(self, x):\n",
        "        classifier = np.dot(x - (self.mean[0] + self.mean[1]) / 2, self.mean[1] - self.mean[0]) - self.trS[0] / (2 * self.N[0]) + self.trS[1] / (2 * self.N[1])\n",
        "        return classifier\n",
        "        \n",
        "    \n",
        "    def GQDA(self, x):\n",
        "        classifier = self.D * la.norm(x - self.mean[0])**2 / self.trS[0] - self.D * la.norm(x - self.mean[1])**2 / self.trS[1] \\\n",
        "                    - self.D * np.log(self.trS[1] / self.trS[0]) - self.D / self.N[0] + self.D / self.N[1]\n",
        "        return classifier\n",
        "    \n",
        "    \n",
        "    def DLDA(self, x):\n",
        "        S_d_inv = np.diag((((self.N[0] - 1) * self.diag[0] + (self.N[1] - 1) * self.diag[1]) / (self.N[0] + self.N[1] - 2))**(-1))\n",
        "        classifier = np.einsum('i, ij, j', x - (self.mean[0] + self.mean[1]) / 2, S_d_inv, self.mean[1] - self.mean[0])\n",
        "        return classifier\n",
        "    \n",
        "    \n",
        "    def DQDA(self, x):\n",
        "        S_d0_inv = np.diag(self.diag[0]**(-1))\n",
        "        S_d1_inv = np.diag(self.diag[1]**(-1))\n",
        "        classifier = np.einsum('i, ij, j', x - self.mean[0], S_d0_inv, x - self.mean[0]) - np.einsum('i, ij, j', x - self.mean[1], S_d1_inv, x - self.mean[1]) \\\n",
        "                                    - np.sum(np.log(self.diag[1])) + np.sum(np.log(self.diag[0]))\n",
        "        return classifier\n",
        "    \n",
        "    \n",
        "    def HM_LSVM(self, x):\n",
        "        svm = SVC(C=float('inf'), kernel='linear')\n",
        "        Y = np.r_[self.X[0], self.X[1]]\n",
        "        y = [-1] * self.N[0] + [1] * self.N[1]\n",
        "        svm.fit(Y, y)\n",
        "        classifier = svm.predict([x])\n",
        "        return classifier\n",
        "        \n",
        "    \n",
        "    def T_DBDA(self, x):\n",
        "        \n",
        "        term1 = np.sum(np.dot(x, self.vec[0].T[r]) * (np.sum(np.dot(self.X[0][j], self.vec_self[0][r, j]) / self.N[0] for j in range(self.N[0])) \n",
        "                       - 1 / 2 * np.dot(self.vec[0].T[r], self.mean[1] - np.sum(np.sum(np.dot(self.X[1][j], self.vec_self[1][s, j]) / self.N[1] for j in range(self.N[1])) \\\n",
        "                                                                                * self.vec[1].T[s] for s in range(self.M[1])))) for r in range(self.M[0]))\n",
        "        \n",
        "        term2 = np.sum(np.dot(x, self.vec[1].T[r])  * (np.sum(np.dot(self.X[1][j], self.vec_self[1][r, j]) / self.N[1] for j in range(self.N[1])) \\\n",
        "                       - 1 / 2 * np.dot(self.vec[1].T[r], self.mean[0] - np.sum(np.sum(np.dot(self.X[0][j], self.vec_self[0][s, j]) / self.N[0] for j in range(self.N[0])) \\\n",
        "                                                                                * self.vec[0].T[s] for s in range(self.M[0])))) for r in range(self.M[1]))\n",
        "        \n",
        "        term3 = np.sum(np.sum(np.sum(np.dot(self.X[0][i], self.vec_self[0][r, i]) * np.dot(self.X[0][j], self.vec_self[0][r, j]) for i in range(j)) for j in range(self.N[0])) \\\n",
        "                      / (self.N[0] * (self.N[0] - 1)) for r in range(self.M[0]))\n",
        "        \n",
        "        term4 = np.sum(np.sum(np.sum(np.dot(self.X[1][i], self.vec_self[1][r, i]) * np.dot(self.X[1][j], self.vec_self[1][r, j]) for i in range(j)) for j in range(self.N[1])) \\\n",
        "                      / (self.N[1] * (self.N[1] - 1)) for r in range(self.M[1]))\n",
        "\n",
        "        classifier = self.DBDA(x) + term1 - term2 - term3 + term4\n",
        "        return classifier\n",
        "    \n",
        "    \n",
        "    \n",
        "    def BCNN(self, x):\n",
        "        term1 = np.zeros(self.N[0])\n",
        "        term2 = np.zeros(self.N[1])\n",
        "        for j in range(self.N[0]):\n",
        "            term1[j] = la.norm(x - self.X[0][j])**2 \\\n",
        "                                - np.sum(np.dot(self.X[0][j], self.vec_self[0][r, j]) for r in range(self.M[0]))  \\\n",
        "                                + 2 * np.sum(np.dot(self.X[0][j], self.vec_self[0][r, j]) * np.dot(x, self.vec[0].T[r]) for r in range(self.M[0])) \\\n",
        "                                - np.sum(np.dot(self.X[0][j], self.vec[1].T[s]) * np.dot(x, self.vec[1].T[s]) for s in range(self.M[1])) \\\n",
        "                                - np.sum(np.sum(np.dot(self.vec[0].T[r], self.vec[1].T[s]) * np.dot(self.X[0][j], self.vec_self[0][r, j]) * np.dot(x, self.vec[1].T[s]) for r in range(self.M[0])) for s in range(self.M[1]))\n",
        "\n",
        "        for j in range(self.N[1]):\n",
        "            term2[j] = la.norm(x - self.X[1][j])**2 \\\n",
        "                                - np.sum(np.dot(self.X[1][j], self.vec_self[1][s, j]) for s in range(self.M[1]))  \\\n",
        "                                + 2 * np.sum(np.dot(self.X[1][j], self.vec_self[1][s, j]) * np.dot(x, self.vec[1].T[s]) for s in range(self.M[1])) \\\n",
        "                                - np.sum(np.dot(self.X[1][j], self.vec[0].T[r]) * np.dot(x, self.vec[0].T[r]) for r in range(self.M[0])) \\\n",
        "                                - np.sum(np.sum(np.dot(self.vec[0].T[r], self.vec[1].T[s]) * np.dot(self.X[1][j], self.vec_self[1][s, j]) * np.dot(x, self.vec[0].T[r]) for r in range(self.M[0])) for s in range(self.M[1]))\n",
        "\n",
        "        classifier = np.min(term1) - np.min(term2) - self.trS[0] + self.trS[1]  \\\n",
        "                    + np.sum(self.value[0][r] for r in range(self.M[0])) - np.sum(self.value[1][s] for s in range(self.M[1]))\n",
        "\n",
        "        return classifier\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eCL42itBfqyB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}